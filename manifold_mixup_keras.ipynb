{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "amtns-2nd layer mix.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gCSfExYLPcC2",
        "g8FxNb4VcfLR",
        "GKjdlRcf469m",
        "3tUR3l024-Fc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIhqi3av40gf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "79c610c8-da52-489b-e093-b0bd078fa373"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjXVjs_Po4kN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x \n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msoXgU6IpeK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        " \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.image import resize\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from datetime import datetime\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHdntytgpsW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "EPOCHS = 20\n",
        "IMG_SIZE = 32\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEVP2BP2UxUn",
        "colab_type": "text"
      },
      "source": [
        "# 1. Loading and preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XZG3W-RsKEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fdda5ee0-cdd2-43ed-d72a-164d00b4c595"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "train_images = preprocess_input(train_images)\n",
        "test_images = preprocess_input(test_images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCSfExYLPcC2",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Subsetting images (If needed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oba3He9XPgGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_unique(train_labels):\n",
        "  unique, counts = np.unique(train_labels, return_counts=True)\n",
        "  return dict(zip(unique, counts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMM0f7phFgi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_per_class = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOg-Hin-NBcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0d6aa75c-f1d5-4d3d-c564-cd2bd1f801eb"
      },
      "source": [
        "subset_train_images = np.empty((num_per_class*10, 32, 32, 3))\n",
        "subset_train_labels = np.empty((num_per_class*10, 1))\n",
        "\n",
        "for i in range(10): \n",
        "  indices = np.random.choice(np.where(train_labels == i)[0], num_per_class, replace = False)\n",
        "  subset_train_images[i*num_per_class: (i+1)*num_per_class] = train_images[indices]\n",
        "  subset_train_labels[i*num_per_class: (i+1)*num_per_class] = train_labels[indices]\n",
        "\n",
        "count_unique(subset_train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0: 1000,\n",
              " 1.0: 1000,\n",
              " 2.0: 1000,\n",
              " 3.0: 1000,\n",
              " 4.0: 1000,\n",
              " 5.0: 1000,\n",
              " 6.0: 1000,\n",
              " 7.0: 1000,\n",
              " 8.0: 1000,\n",
              " 9.0: 1000}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OVvbY9QP3Vc",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Convert images into tf tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFH4RjoacdBh",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1 Full dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG7C-mb3cYX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1030008e-bb37-473c-a6ba-f8457ccc8ea4"
      },
      "source": [
        "train_labels = keras.utils.to_categorical(train_labels)\n",
        "test_labels = keras.utils.to_categorical(test_labels)\n",
        "\n",
        "train_images = tf.convert_to_tensor(train_images)\n",
        "test_images = tf.convert_to_tensor(test_images)\n",
        "\n",
        "train_labels = tf.convert_to_tensor(train_labels)\n",
        "test_labels = tf.convert_to_tensor(test_labels)\n",
        "\n",
        "print(train_images.shape, train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (50000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8FxNb4VcfLR",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.2 Subset of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuwDAsdnjyTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p,], b[p,]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVLW7ijEjzPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images, train_labels = unison_shuffled_copies(subset_train_images, subset_train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v34T_l0s7T1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ea0bb16-7631-467b-8c49-96a9ff25d51b"
      },
      "source": [
        "train_labels = keras.utils.to_categorical(train_labels)\n",
        "test_labels = keras.utils.to_categorical(test_labels)\n",
        "\n",
        "train_images = tf.convert_to_tensor(train_images, dtype=tf.dtypes.float32)\n",
        "test_images = tf.convert_to_tensor(test_images)\n",
        "\n",
        "train_labels = tf.convert_to_tensor(train_labels)\n",
        "test_labels = tf.convert_to_tensor(test_labels)\n",
        "\n",
        "print(train_images.shape, train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 3) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsugA_GxU0z0",
        "colab_type": "text"
      },
      "source": [
        "# 2. Base model - VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T_Uf0vJqro4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6f419c51-d441-437a-83ca-a2775989031f"
      },
      "source": [
        "vgg_model = VGG16(input_shape = IMG_SHAPE,\n",
        "                  include_top = False,\n",
        "                  weights = 'imagenet')\n",
        "                  \n",
        "vgg_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCehuQSHAkPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers_to_use = [l for l in vgg_model.layers]\n",
        "\n",
        "# layers_to_use.insert(1, layers.UpSampling2D(size=(7, 7)))\n",
        "layers_to_use.insert(1, layers.Lambda(lambda image: tf.image.resize(image, size=(224, 224))))\n",
        "layers_to_use.append(layers.Flatten())\n",
        "layers_to_use.append(layers.Dense(4096, activation = 'relu', name = 'first_dense'))\n",
        "layers_to_use.append(layers.Dense(4096, activation = 'relu', name = 'second_dense'))\n",
        "layers_to_use.append(layers.Dense(10, activation = 'softmax', name = 'output_layer'))\n",
        "\n",
        "base_model = keras.Sequential(\n",
        "                              layers_to_use\n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-taDZnnmNzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mix_layer = 12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehkJ_cvrdBPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "intermediate_layer_model = keras.Sequential(layers_to_use[0:mix_layer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqDZw472Z7m4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_model = keras.Sequential(layers_to_use[mix_layer:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klOnwjla2Y1-",
        "colab_type": "text"
      },
      "source": [
        "# 3. Extended model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKjdlRcf469m",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 For mixup training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVQKRjPYNd6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = layers.Input(25088)\n",
        "first_dense = layers.Dense(4096, activation = 'relu')(input_layer)\n",
        "second_dense = layers.Dense(4096, activation = 'relu')(first_dense)\n",
        "output_layer = layers.Dense(10, activation = 'softmax')(second_dense)\n",
        "\n",
        "model = keras.Model(\n",
        "                    inputs = input_layer,\n",
        "                    outputs = output_layer\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR_vYhe8LKX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7HHy5KjL31O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83ca1adb-d4f3-4fb7-8655-578f03ae834e"
      },
      "source": [
        "for x_batch_val, y_batch_val in val_dataset:\n",
        "    test_step(x_batch_val, y_batch_val)\n",
        "\n",
        "print(\"Validation acc:\", (float(val_acc_metric.result())))\n",
        "val_acc_metric.reset_states()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation acc: 0.8551999926567078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tUR3l024-Fc",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 For regular training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-B72OBQ-YW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers_to_use.extend((layers.Dense(4096, activation = 'relu'),\n",
        "                          layers.Dense(4096, activation = 'relu'),\n",
        "                          layers.Dense(10, activation = 'softmax')))\n",
        "\n",
        "model = keras.Sequential(\n",
        "                          layers_to_use \n",
        "                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo5Qsk9uOrTX",
        "colab_type": "text"
      },
      "source": [
        "# 4. Training with Mixup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TRo9PuX6Lgz",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 Mixup with alpha for each sample of the batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpE3lw9porsj",
        "colab_type": "text"
      },
      "source": [
        "### 4.1.1 Mixup function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSgOUPYcXkXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def data_mixup(data, labels):\n",
        "\n",
        "    '''This function performs mixup of data and labels.\n",
        "    It uses an alpha value for each sample in the batch\n",
        "    data = input data\n",
        "    labels = labels of input data\n",
        "    '''\n",
        "\n",
        "    num_data = int(data.shape[0]/2)\n",
        "\n",
        "    data = tf.reshape(data, shape=(num_data, 2, *[shape for shape in data.shape[1:]]))\n",
        "\n",
        "    labels = tf.reshape(labels, shape=(num_data, 2, 10))\n",
        "\n",
        "    alpha = np.random.beta(0.5, 0.5, (1, num_data))\n",
        "    alpha_mat = tf.convert_to_tensor(np.concatenate((alpha, (1-alpha)), axis=0), dtype = tf.dtypes.float32)\n",
        "\n",
        "    data_list = []\n",
        "    labels_list = []\n",
        "    \n",
        "    for i in range(num_data):\n",
        "      alpha_mat[:,i]\n",
        "      data_list.append((tf.tensordot(data[i], alpha_mat[:,i], axes = [0, 0])))\n",
        "      labels_list.append((tf.tensordot(labels[i], alpha_mat[:,i], axes=[0, 0])))\n",
        "\n",
        "\n",
        "    mixed_data = tf.stack(data_list)\n",
        "    mixed_labels = tf.stack(labels_list)\n",
        "\n",
        "    return mixed_data, mixed_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Leqdycjzo2L2",
        "colab_type": "text"
      },
      "source": [
        "### 4.1.2 Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do8gcwYRj3fU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH = 64\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "val_dataset = val_dataset.batch(64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnZfOXqOneQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.experimental.enable_mixed_precision_graph_rewrite(keras.optimizers.SGD(learning_rate = 0.001))\n",
        "loss_fn = keras.losses.BinaryCrossentropy()\n",
        "\n",
        "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "val_acc_metric = keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-91KDbMGfP06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        x = intermediate_layer_model(x)\n",
        "        x, y = data_mixup(x, y)\n",
        "        model_output = output_model(x, training=True)\n",
        "\n",
        "        loss_value = loss_fn(y, model_output)\n",
        "\n",
        "    grads = tape.gradient(loss_value, base_model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, base_model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, model_output)\n",
        "    return loss_value\n",
        "\n",
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    model_output_val = base_model(x, training=False)\n",
        "    val_acc_metric.update_state(y, model_output_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96lUEFxH-kyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_acc_history = np.empty(EPOCHS)\n",
        "val_acc_history = np.empty(EPOCHS)\n",
        "loss_value_history = np.empty(EPOCHS)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):   \n",
        "        \n",
        "        # x_batch_train = base_model(x_batch_train)\n",
        "        # x_batch_train_mixed, y_batch_train_mixed = data_mixup(x_batch_train, y_batch_train, mixup='manifold')   \n",
        "\n",
        "        # loss_value = train_step(x_batch_train_mixed, y_batch_train_mixed)\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "      \n",
        "\n",
        "        if step % 100 == 0 and step > 0:\n",
        "            print(\"Training loss (for one batch)\", (float(loss_value)))\n",
        "            print(\"Training accuracy so far\", float(train_acc_metric.result()))\n",
        "            print(\"Seen so far: %s samples\" % (step * BATCH))\n",
        "\n",
        "    train_acc_history[epoch] = train_acc_metric.result()\n",
        "    loss_value_history[epoch] = loss_value\n",
        "\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        test_step(x_batch_val, y_batch_val)\n",
        "\n",
        "    print(\"Validation acc:\", (float(val_acc_metric.result())))\n",
        "    print(\"Time taken:\", (time.time() - start_time))\n",
        "    val_acc_history[epoch] = val_acc_metric.result()\n",
        "    val_acc_metric.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk32Wjp-ac4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('/content/drive/My Drive/Colab Notebooks/model_man_full_allalpha_20epochs.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y4z3OJKUepz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving history in csv. format\n",
        "\n",
        "hist_df = pd.DataFrame(history.history) \n",
        " \n",
        "hist_csv_file = '/content/drive/My Drive/Colab Notebooks/history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQevb5HAg1Jw",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 Single alpha mixup training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR30bGt2oUcK",
        "colab_type": "text"
      },
      "source": [
        "### 4.2.1 Mixup function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgY5UyAzSHA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def data_mixup_single_alpha(data, labels):\n",
        "\n",
        "    '''This function performs mixup of data and labels.\n",
        "    It uses an alpha value for each sample in the batch\n",
        "    data = input data\n",
        "    labels = labels of input data\n",
        "    '''\n",
        "\n",
        "    num_data = int(data.shape[0]/2)\n",
        "\n",
        "    data = tf.reshape(data, shape=(num_data, 2, *[shape for shape in data.shape[1:]]))\n",
        "      \n",
        "    labels = tf.reshape(labels, shape=(num_data, 2, 10))\n",
        "\n",
        "    # alpha = np.random.uniform(0, 1, (1))\n",
        "    alpha = np.random.beta(0.5, 0.5, (1))\n",
        "    alpha_mat = tf.convert_to_tensor(np.concatenate((alpha, (1-alpha)), axis=0), dtype = tf.dtypes.float32)\n",
        "\n",
        "    mixed_data = tf.tensordot(data, alpha_mat,axes=[1,0])\n",
        "    mixed_labels = tf.tensordot(labels, alpha_mat,axes=[1,0])\n",
        "\n",
        "\n",
        "    return mixed_data, mixed_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_jW9e2Job-V",
        "colab_type": "text"
      },
      "source": [
        "### 4.2.2 Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfGVhEgoRhzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH = 64\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "val_dataset = val_dataset.batch(64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJiVd95FRiLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.experimental.enable_mixed_precision_graph_rewrite(keras.optimizers.SGD(learning_rate = 0.0001))\n",
        "loss_fn = keras.losses.BinaryCrossentropy()\n",
        "\n",
        "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "val_acc_metric = keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fCijFwYUhFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        x = intermediate_layer_model(x)\n",
        "        x, y = data_mixup(x, y)\n",
        "        model_output = output_model(x, training=True)\n",
        "\n",
        "        loss_value = loss_fn(y, model_output)\n",
        "\n",
        "    grads = tape.gradient(loss_value, base_model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, base_model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, model_output)\n",
        "    return loss_value\n",
        "\n",
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    model_output_val = base_model(x, training=False)\n",
        "    val_acc_metric.update_state(y, model_output_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTRzhoE37S7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_acc_history = np.empty(EPOCHS)\n",
        "val_acc_history = np.empty(EPOCHS)\n",
        "loss_value_history = np.empty(EPOCHS)\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):   \n",
        "\n",
        "        # x_batch_train_mixed, y_batch_train_mixed = data_mixup_single_alpha(x_batch_train, y_batch_train)   \n",
        "\n",
        "        loss_value = train_step(x_batch_train, y_batch_train)\n",
        "      \n",
        "\n",
        "        if step % 100 == 0 and step > 0:\n",
        "            print(\"Training loss (for one batch)\", (float(loss_value)))\n",
        "            print(\"Training accuracy so far\", float(train_acc_metric.result()))\n",
        "            print(\"Seen so far: %s samples\" % (step * BATCH))\n",
        "\n",
        "    train_acc_history[epoch] = train_acc_metric.result()\n",
        "    loss_value_history[epoch] = loss_value\n",
        "\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        test_step(x_batch_val, y_batch_val)\n",
        "\n",
        "    print(\"Validation acc:\", (float(val_acc_metric.result())))\n",
        "    print(\"Time taken:\", (time.time() - start_time))\n",
        "    val_acc_history[epoch] = val_acc_metric.result()\n",
        "    val_acc_metric.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZiRGPhHQIJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving history in csv. format\n",
        "\n",
        "hist_df = pd.DataFrame(history.history) \n",
        " \n",
        "hist_csv_file = '/content/drive/My Drive/Colab Notebooks/history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV2TulYQWC42",
        "colab_type": "text"
      },
      "source": [
        "# 5. Training without mixup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSIoefba-6Xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = keras.optimizers.SGD(learning_rate = 0.001), \n",
        "              loss = keras.losses.CategoricalCrossentropy(), \n",
        "              metrics = keras.metrics.CategoricalAccuracy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJPbLJceG5hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "start = time.time()\n",
        "history = model.fit(\n",
        "                    train_images,\n",
        "                    train_labels, \n",
        "                    batch_size=64,\n",
        "                    epochs=1, \n",
        "                    callbacks=[tensorboard_callback],\n",
        "                    validation_data=(test_images, test_labels)\n",
        "                    )\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATSZiFe6alrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving history in csv. format\n",
        "\n",
        "hist_df = pd.DataFrame(history.history) \n",
        " \n",
        "hist_csv_file = '/content/drive/My Drive/Colab Notebooks/history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPzjYSsy0Twm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN7EBc4D6HEA",
        "colab_type": "text"
      },
      "source": [
        "# 6. Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtMZ9fJIhrtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHu1lCgFzbn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F52mr_aQ6I3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_pd = pd.read_csv('/content/drive/My Drive/Colab Notebooks/reg.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJzaAEHR6Pja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noreg_pd = pd.read_csv('/content/drive/My Drive/Colab Notebooks/noreg.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd-VO8dj6Tv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_pd = reg_pd.drop(columns=['No'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQBJ3Z906f3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noreg_pd = noreg_pd.drop(columns=['No'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY9RUmbS6iOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np.arange(1, 21)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(y, reg_pd['5000'], label='5000 per class')\n",
        "plt.plot(y, reg_pd['4000'], label='4000 per class')\n",
        "plt.plot(y, reg_pd['3000'], label='3000 per class')\n",
        "plt.plot(y, reg_pd['2000'], label='2000 per class')\n",
        "plt.plot(y, reg_pd['1000'], label='1000 per class')\n",
        "plt.annotate(s = str(0.860),  xy=(19, 0.87), fontsize=12)\n",
        "plt.annotate(s = str(0.856),  xy=(19, 0.85), fontsize=12)\n",
        "plt.annotate(s = str(0.822),  xy=(19, 0.83), fontsize=12)\n",
        "plt.annotate(s = str(0.816),  xy=(19, 0.80), fontsize=12)\n",
        "plt.annotate(s = str(0.770),  xy=(19, 0.77), fontsize=12)\n",
        "plt.xticks(y , ('1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20'))\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Accuracy per epoch (Mixup)', fontsize=22)\n",
        "plt.ylabel('Accuracy in percent', fontsize=18)\n",
        "plt.xlabel('Epoch', fontsize=18)\n",
        "plt.ylim([0.4, 1])\n",
        "plt.tick_params(axis='both', which='major', labelsize=12)\n",
        "plt.savefig('/content/drive/My Drive/Colab Notebooks/reg.png')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh1l8wTS8sNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np.arange(1, 21)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(y, noreg_pd['5000'], label='5000 per class')\n",
        "plt.plot(y, noreg_pd['4000'], label='4000 per class')\n",
        "plt.plot(y, noreg_pd['3000'], label='3000 per class')\n",
        "plt.plot(y, noreg_pd['2000'], label='2000 per class')\n",
        "plt.plot(y, noreg_pd['1000'], label='1000 per class')\n",
        "plt.annotate(s = str(0.864),  xy=(19, 0.87), fontsize=12)\n",
        "plt.annotate(s = str(0.858),  xy=(19, 0.85), fontsize=12)\n",
        "plt.annotate(s = str(0.842),  xy=(19, 0.829), fontsize=12)\n",
        "plt.annotate(s = str(0.833),  xy=(19, 0.81), fontsize=12)\n",
        "plt.annotate(s = str(0.791),  xy=(19, 0.78), fontsize=12)\n",
        "plt.xticks(y, ('1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20'))\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.title('Accuracy per epoch (No Mixup)', fontsize=22)\n",
        "plt.ylabel('Accuracy in percent', fontsize=18)\n",
        "plt.xlabel('Epoch', fontsize=18)\n",
        "plt.ylim([0.4, 1])\n",
        "plt.tick_params(axis='both', which='major', labelsize=12)\n",
        "plt.savefig('/content/drive/My Drive/Colab Notebooks/noreg.png')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-yDDhqoBGX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final = pd.read_csv('/content/drive/My Drive/Colab Notebooks/final.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gx5sO6dC2AX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot([5000, 4000, 3000, 2000, 1000], final['No Mixup'][0:5], label='No Mixup')\n",
        "plt.plot([5000, 4000, 3000, 2000, 1000], final['Mixup'][0:5], label='Mixup')\n",
        "plt.annotate(s = str(0.860),  xy=(4930, 0.857), fontsize=12)\n",
        "plt.annotate(s = str(0.856),  xy=(4000, 0.850), fontsize=12)\n",
        "plt.annotate(s = str(0.822),  xy=(3000, 0.822), fontsize=12)\n",
        "plt.annotate(s = str(0.816),  xy=(2000, 0.81), fontsize=12)\n",
        "plt.annotate(s = str(0.770),  xy=(1000, 0.77), fontsize=12)\n",
        "plt.annotate(s = str(0.864),  xy=(4930, 0.868), fontsize=12)\n",
        "plt.annotate(s = str(0.858),  xy=(4000, 0.863), fontsize=12)\n",
        "plt.annotate(s = str(0.842),  xy=(3000, 0.845), fontsize=12)\n",
        "plt.annotate(s = str(0.833),  xy=(2000, 0.835), fontsize=12)\n",
        "plt.annotate(s = str(0.791),  xy=(1000, 0.792), fontsize=12)\n",
        "plt.xticks([5000, 4000, 3000, 2000, 1000], ('5000','4000', '3000', '2000', '1000'))\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.title('Last epoch accuracy per subset size', fontsize=22)\n",
        "plt.ylabel('Accuracy in percent', fontsize=18)\n",
        "plt.xlabel('Subset size', fontsize=18)\n",
        "plt.ylim([0.6, 1])\n",
        "plt.tick_params(axis='both', which='major', labelsize=12)\n",
        "plt.savefig('/content/drive/My Drive/Colab Notebooks/final.png')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhBZKDyFTpoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCXtvVqPTrEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}